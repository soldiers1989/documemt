##概述
在网站系统里面定时任务是一个重要和不可缺的角色，很多地方需要使用定时执行一项任务。比如，订单系统的接单超时、支付超时，结算系统的定时结算、奖励计算，第三方的认证信息刷新（微信的token），dsp等推广平台数据定时对接，缓存数据的定时更新等。

##定时任务实现方式
###Timmer定时器
这时最简单和最基础的了，学习过计算机课程的都能知道也都能写。

虽然常见，这里也简单的说几个点：

####触发时间点
Timmer有两种指定执行时间的方式，一种是给一个时间间隔（Interval），另一种就是给定一个具体的执行时间。

![这里写图片描述](http://img.blog.csdn.net/20160611180955800)

这时，timer的所有方法，其中画红圈圈的。第一个是在指定的时间点触发，给的参数是一个Date类型；第二个是按照指定的时间间隔触发，给的参数是一个long类型。这两种在实际工程中都是会被用到的。

####Timer和TimerTask之间的关系

先看一个最常见的Timer使用示例：

```java
public class MyTimeTask {
   public static void main(String[] args){
      Timer timer = new Timer(); 
      timer.schedule(new MyTask1(), 60 * 1000);
      timer.schedule(new MyTask2(), 120 * 1000);
    }

	class MyTask1 extends TimerTask {
	   public void run(){
	    System.out.println("running1....");
	  }
	}
	
	class MyTask2 extends TimerTask {
	   public void run(){
	    System.out.println("running2....");
	  }
	}
}
```

可以看到，一个Timer是可以调度多个Task的，这个也可以从Timer的源代码看出来：
![这里写图片描述](http://img.blog.csdn.net/20160611182349852)

mainloop循环在不断的读取queue中的task，逐个执行。对于按间隔期不断执行的task，会被计算下次执行时间后被重新放入到队列中。

这里的queue是一个优先级队列，会按照task的执行时间排序，最近的task会被先取出来执行。
![这里写图片描述](http://img.blog.csdn.net/20160611182535509)

这里想说的是什么呢，在工程中最好不要一个task就创建一个timer，这样有点过于浪费系统资源，因为一个timer就是一个线程，而且在不断的消耗系统的cpu资源。

###quartz
quartz是java里面最流行的定时任务调度框架，python里面的定时任务框架APScheduler也是基于Quartz，实现了Quartz的所有功能。
这里把quartz的内容多介绍一些，因为后续集群部分涉及到的elastic-job，同样是基于quartz实现的。要了解更多关于quartz的只是，推荐两个网站：
官网教程目录页
> http://www.quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/

以梦为马的个人博客（一个系列的3篇）
>http://blog.csdn.net/ahmuamu/article/details/50364769


quartz的只要构成是schedule、trigger、job三元素的体系，体系中还提供了三者各自的Listener用来监听他们的事件和对事件作出响应。以下是一个最原始的、最基础的quartz使用示例代码（来自官网）：
```java
  SchedulerFactory schedFact = new org.quartz.impl.StdSchedulerFactory();

  Scheduler sched = schedFact.getScheduler();

  sched.start();

  // define the job and tie it to our HelloJob class
  JobDetail job = newJob(HelloJob.class)
      .withIdentity("myJob", "group1")
      .build();

  // Trigger the job to run now, and then every 40 seconds
  Trigger trigger = newTrigger()
      .withIdentity("myTrigger", "group1")
      .startNow()
      .withSchedule(simpleSchedule()
          .withIntervalInSeconds(40)
          .repeatForever())
      .build();

  // Tell quartz to schedule the job using our trigger
  sched.scheduleJob(job, trigger);
```
贴在这里，是为了让大家理解三者之间的关系。job封装任务执行的代码，trigger封装任务执行的时间信息，schedule绑定job和trigger执行任务调度。

在java世界里，spring已经是无所不在，接下来简单的看一下spring集成quartz需要做的事情（理解的上述的代码，也就容易理解，为什么spring配置文件里要配置这些东西了）。

1.首先就是要把quartz的包引入进来，添加maven引用：
```java
<dependency>
	<groupId>org.quartz-scheduler</groupId>
		<artifactId>quartz</artifactId>
	<version>${quartz.version}</version>
</dependency>
```

2.定义job，定义job有两种方式，一种是使用MethodInvokingJobDetailFactoryBean封装自己的bean，这样自己的bean可以是一个任意的pojo；第二种是使用JobDetailFactoryBean，同时让自己的job扩展QuartzJobBean，实现executeInternal的抽象方法。

具体可以参加（这里给的比较详细）：http://websystique.com/spring/spring-4-quartz-scheduler-integration-example/

3.定义trigger
这里可以定义简单的trigger（SimpleTriggerFactoryBean），他使用的是jdk的timer做为调度；也可以定义一个cron表达式类型的trigger（CronTriggerFactoryBean）去定义一个更语义化的触发表达式。

关于cron表达式的知识，可以参见这里：http://www.quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-06.html

4.定义scheduler，绑定trigger和job


###spring-scheduled注解
spring自己也提供了一个轻量级的定时任务工具，而且是在core包里面。可以使用scheduled注解，也可以仅使用xml配置。虽然说它轻量级，但是他实现了quartz支持的两种时间触发机制，简单的和cron表达式的。说他轻量级，也是因为他不能支持quartz能够支持的集群功能。

这里先推荐一个spring的官方版本（如果对spring-scheduled没有概念，需要先查baidu了解一些之后再看这里，因为这个写的比较简洁）：http://spring.io/guides/gs/scheduling-tasks/

接下来一块看下scheduled的注解使用，也是两种用法，一个是普通的timer类似调度，一种是cron表达式方式调度。

这里只看cron表达是方式的，普通方式的请见上述网址。以下示例来自于http://howtodoinjava.com/。关于spring-scheduled的使用推荐以下几个网址：
>http://howtodoinjava.com/spring/spring-core/4-ways-to-schedule-tasks-in-spring-3-scheduled-example/
>http://www.cnblogs.com/Gyoung/p/5339242.html
>http://spring.io/guides/gs/scheduling-tasks/

1.引入task命名空间,开启注解自动识别
```java
< ?xml  version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 xmlns:task="http://www.springframework.org/schema/task"
 xmlns:util="http://www.springframework.org/schema/util"
 xmlns:context="http://www.springframework.org/schema/context"
 xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd
http://www.springframework.org/schema/context/ http://www.springframework.org/schema/context/spring-context.xsd
http://www.springframework.org/schema/util/ http://www.springframework.org/schema/util/spring-util.xsd
http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.0.xsd">
 
    <task:annotation-driven />

</beans>
```

2.在需要调度的方法上添加@scheduled注解
```java
@Scheduled(fixedDelay =30000)
public void demoServiceMethod () {... }

@Scheduled(fixedRate=30000)
public void demoServiceMethod () {... }

@Scheduled(cron="0 0 * * * *")
public void demoServiceMethod () {... }
```

##分布式场景
什么是分布式场景呢，当单台服务器服务能力不够的时候，就需要更多的服务器进行水平向的扩展，由多台服务器分工（任务量上的水平划分，而非业务线上的垂直划分）的方式来增强服务能力，提供更强的并发请求处理，更短的时间响应。

像第一节说到的定时任务使用场景，大多是一次任务执行仅能有一个服务器在执行，如果是所有服务器都在执行相同的任务，一个是会造成错误，就算不会造成错误，很多服务器在做重复的工作也是极大的浪费。

所以，分布式场景下定时任务要做的一个基本难点就是：怎么让某一个定时任务，在一个触发时点上仅有一台服务器在执行。

更进一步，如果，你的定时任务涉及到很多同类型的数据要处理，比如说要处理100个输入文件，处理方式相同；再比如说你的数据库已经做了分库处理，业务数据被写入到了10个数据库实例中，处理方式相同。那么此时，可以让更多台服务器执行定时任务，每台执行其中的一部分，比如10个输入文件；再比如1个数据库实例中的业务数据。

以上两种场景怎么办呢？第一种很简单，后续会提供三种方式去做：1.设置某一台为任务执行服务器，其他服务器不执行；2.使用quartz的集群功能，实现某一台执行；3.使用当当开源的elastic-job，实现某一台执行。第二种场景只有第一种场景中的第3中方式可以做到。

接下来逐个看一下。

##实现分布式的方式
###设置某一台为任务执行服务器
这种方式可以采用环境变量的方式来实现，定时任务运行时检查本机的环境变量值是否为可执行，如果是则执行定时任务，如果不是则直接返回。
```java
@Value("${ISTIMERRUNNER}")
private String isTimerRunner;
	
@Scheduled(cron="0 0 0  * * ? ")
public void task(){
	try {
		if("true".equals(isTimerRunner)){
				//do something.....
			}
		} catch (Exception e) {
			e.printStackTrace();
		}
	}
```

这里有一个需要注意的事项，如果集群环境下，你使用了脚本部署的方式，而且是类似于作者的方式。也就是先把文件拷贝到一台服务器，启动好后，调用脚本（脚本参见：http://blog.csdn.net/buqutianya/article/details/51062384），逐个部署到其他服务器。那么，你就需要注意一下了。

远程ssh调用startup.sh时，tomcat取不到环境变量，这里需要把startup.sh的顶部进行修改：
```java
#!/bin/sh --login
```

当然这里还有另外一种方式，就是在tomcat的bin目录中添加一个setenv.sh文件，startup.sh执行时会加载其中的内容。
```
export ISTIMERRUNNER=true
```

这种方式有十分明显的缺陷：1.单点，当任务执行节点出现问题时，整个定时任务全部over；2.资源分配不均衡，随着定时任务的增多，任务执行服务器的资源占用压力会越来越大。

当然了，这是在技术能力不够的时候，最简单有效的实现方式。

###使用quartz的集群功能
quartz这个老牌的定时任务执行工具，在集群方面也提供了很好的支持。quartz的集群是借助数据库来实现的，所有的服务器实例共享一套数据库表中存储的任务、触发器和调度器信息，实现一个时间点，同一个任务仅有一台服务器在执行。而且提供了负载均衡和failover失败转移功能。

quartz的负载均衡大概是这样的策略：对于需要调度很多任务的调度器，会近似随机的选择服务器执行；对于调度的任务数比较少的（1个或者2个）的触发器，会尽量的在同一台服务器上执行。（可以参见这里:http://www.quartz-scheduler.org/documentation/quartz-2.2.x/tutorials/tutorial-lesson-11.html）

quartz的集群使用也不复杂，接下来一起看一下：

1.导入数据库表

quartz的集群是基于数据库实现的，所以首先要把数据库表结构创建好。创建脚本在quartz的完整下载包里可以找到（官网下载地址：http://www.quartz-scheduler.org/downloads/）。

解压之后，在docs/dbTable目录下可以找到你想要的所有常见数据库类型的创建脚本。

![这里写图片描述](http://img.blog.csdn.net/20160611221509339)

我使用的是sql数据库，所以使用了tables_mysql_innodb.sql。

这里导入的时候遇到了一个问题，就是创建索引时索引字段过长。这里我采用的方法是把所有的scheduler的长度变成了50，修改之后也就是会限制所有的scheduler的名字在50个字节以内。

2.创建支持集群的scheduler
集群和非集群的配置不同，关键就在于scheduler，集群时需要给scheduler配置数据源、将org.quartz.jobStore.isClustered设置为true、以及配置quartz.properties属性文件。详细的实现方式可以参见：http://sundoctor.iteye.com/blog/486055

###使用elastic-job
elastic-job是基于quartz实现的，最大的不同点是elastic-job把做为共享中心的数据库换成了zookeeper。所以要使用elastic-job首先要安装zookeeper。

安装好zookeeper之后，使用elastic-job也不难，它做了很好的spring集成支持，只需要配置注册中心和执行任务的job即可。

以下是一个配置文件的示例：
```java
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:context="http://www.springframework.org/schema/context" 
    xmlns:reg="http://www.dangdang.com/schema/ddframe/reg" 
    xmlns:job="http://www.dangdang.com/schema/ddframe/job" 
    xsi:schemaLocation="http://www.springframework.org/schema/beans 
                        http://www.springframework.org/schema/beans/spring-beans.xsd 
                        http://www.springframework.org/schema/context 
                        http://www.springframework.org/schema/context/spring-context.xsd 
                        http://www.dangdang.com/schema/ddframe/reg 
                        http://www.dangdang.com/schema/ddframe/reg/reg.xsd 
                        http://www.dangdang.com/schema/ddframe/job 
                        http://www.dangdang.com/schema/ddframe/job/job.xsd 
                        ">
    <context:component-scan base-package="com.dangdang.example.elasticjob" />
    <context:property-placeholder location="classpath:conf/*.properties" />
    
    <reg:zookeeper id="regCenter" server-lists="${serverLists}" namespace="${namespace}" base-sleep-time-milliseconds="${baseSleepTimeMilliseconds}" max-sleep-time-milliseconds="${maxSleepTimeMilliseconds}" max-retries="${maxRetries}" nested-port="${nestedPort}" nested-data-dir="${nestedDataDir}" />
    
    <job:simple id="simpleElasticJob" class="com.dangdang.example.elasticjob.spring.job.SimpleJobDemo" registry-center-ref="regCenter" sharding-total-count="${simpleJob.shardingTotalCount}" cron="${simpleJob.cron}" sharding-item-parameters="${simpleJob.shardingItemParameters}" monitor-execution="${simpleJob.monitorExecution}" monitor-port="${simpleJob.monitorPort}" failover="${simpleJob.failover}" description="${simpleJob.description}" disabled="${simpleJob.disabled}" overwrite="${simpleJob.overwrite}" />
</beans>

```


更详细的示例可以到github下载：https://github.com/ZhangShufan15/elastic-job


这里简单的说一下elastic-job相对于quartz的优势：

1.使用zookeeper做为协调，更加轻量级，这一点对于使用者来说也是一个困难项，因为无论再小的服务也有一个数据库，所以定时任务也使用数据库，那么用起来省事一点。但使用zookeeper一方面速度快，另一方面是不占用现有数据库的连接和计算资源。

2.支持任务的分片，quartz同一时点，同一任务只能在一台机器上运行，但是elastic-job可以在多台机器上运行，并且能够指定每台服务器上运行的输入分片。比如业务数据在10个数据库，这里总共有5台服务器，那么每台服务器在同一个时点，仅处理其中的2个数据库。做到将可纵向切分的任务，切分给不同的服务器，充分利用资源，加快计算速度。

elastic-job怎么做到的分片，在不同的场景下我们该怎么使用elastic-job，接下来的一节将从源代码的角度进行讲解。


##集成elastic-job
1.首先引入maven仓库
```java
<!-- 引入elastic-job核心模块 -->
<dependency>
    <groupId>com.dangdang</groupId>
    <artifactId>elastic-job-core</artifactId>
    <version>1.1.0</version>
</dependency>

<!-- 使用springframework自定义命名空间时引入 -->
<dependency>
    <groupId>com.dangdang</groupId>
    <artifactId>elastic-job-spring</artifactId>
    <version>1.1.0</version>
</dependency>
```

2.实现自己定义的作业
```java
@Component
public class MyElasticJob extends AbstractSimpleElasticJob {

    @Override
    public void process(JobExecutionMultipleShardingContext context) {
        // do something by sharding items
    }
}
```

3.配置作业

```java

<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:context="http://www.springframework.org/schema/context" 
    xmlns:reg="http://www.dangdang.com/schema/ddframe/reg" 
    xmlns:job="http://www.dangdang.com/schema/ddframe/job" 
    xsi:schemaLocation="http://www.springframework.org/schema/beans 
                        http://www.springframework.org/schema/beans/spring-beans.xsd 
                        http://www.springframework.org/schema/context 
                        http://www.springframework.org/schema/context/spring-context.xsd 
                        http://www.dangdang.com/schema/ddframe/reg 
                        http://www.dangdang.com/schema/ddframe/reg/reg.xsd 
                        http://www.dangdang.com/schema/ddframe/job 
                        http://www.dangdang.com/schema/ddframe/job/job.xsd 
                        ">
    <context:component-scan base-package="com.dangdang.example.elasticjob" />
    <context:property-placeholder location="classpath:conf/*.properties" />
    
    <reg:zookeeper id="regCenter" server-lists="${serverLists}" namespace="${namespace}" base-sleep-time-milliseconds="${baseSleepTimeMilliseconds}" max-sleep-time-milliseconds="${maxSleepTimeMilliseconds}" max-retries="${maxRetries}" nested-port="${nestedPort}" nested-data-dir="${nestedDataDir}" />
    
    <job:simple id="simpleElasticJob" class="com.dangdang.example.elasticjob.spring.job.SimpleJobDemo" registry-center-ref="regCenter" sharding-total-count="${simpleJob.shardingTotalCount}" cron="${simpleJob.cron}" sharding-item-parameters="${simpleJob.shardingItemParameters}" monitor-execution="${simpleJob.monitorExecution}" monitor-port="${simpleJob.monitorPort}" failover="${simpleJob.failover}" description="${simpleJob.description}" disabled="${simpleJob.disabled}" overwrite="${simpleJob.overwrite}" />
    <job:dataflow id="throughputDataFlowJob" class="com.dangdang.example.elasticjob.spring.job.ThroughputDataFlowJobDemo" registry-center-ref="regCenter" sharding-total-count="${throughputDataFlowJob.shardingTotalCount}" cron="${throughputDataFlowJob.cron}" sharding-item-parameters="${throughputDataFlowJob.shardingItemParameters}" monitor-execution="${throughputDataFlowJob.monitorExecution}" failover="${throughputDataFlowJob.failover}" process-count-interval-seconds="${throughputDataFlowJob.processCountIntervalSeconds}" concurrent-data-process-thread-count="${throughputDataFlowJob.concurrentDataProcessThreadCount}" description="${throughputDataFlowJob.description}" disabled="${throughputDataFlowJob.disabled}" overwrite="${throughputDataFlowJob.overwrite}" streaming-process="${throughputDataFlowJob.streamingProcess}" />
    <job:dataflow id="sequenceDataFlowJob" class="com.dangdang.example.elasticjob.spring.job.SequenceDataFlowJobDemo" registry-center-ref="regCenter" sharding-total-count="${sequenceDataFlowJob.shardingTotalCount}" cron="${sequenceDataFlowJob.cron}" sharding-item-parameters="${sequenceDataFlowJob.shardingItemParameters}" monitor-execution="${sequenceDataFlowJob.monitorExecution}" failover="${sequenceDataFlowJob.failover}" process-count-interval-seconds="${sequenceDataFlowJob.processCountIntervalSeconds}" max-time-diff-seconds="${sequenceDataFlowJob.maxTimeDiffSeconds}" description="${sequenceDataFlowJob.description}" disabled="${sequenceDataFlowJob.disabled}" overwrite="${sequenceDataFlowJob.overwrite}" />
</beans>
```

属性文件定义:
```java
#job.properties

simpleJob.cron=0/5 * * * * ?
simpleJob.shardingTotalCount=10
simpleJob.shardingItemParameters=0=A,1=B,2=C,3=D,4=E,5=F,6=G,7=H,8=I,9=J
simpleJob.monitorExecution=false
simpleJob.failover=true
simpleJob.description=\u53EA\u8FD0\u884C\u4E00\u6B21\u7684\u4F5C\u4E1A\u793A\u4F8B
simpleJob.disabled=false
simpleJob.overwrite=true
simpleJob.monitorPort=9888

throughputDataFlowJob.cron=0/5 * * * * ?
throughputDataFlowJob.shardingTotalCount=10
throughputDataFlowJob.shardingItemParameters=0=A,1=B,2=C,3=D,4=E,5=F,6=G,7=H,8=I,9=J
throughputDataFlowJob.monitorExecution=true
throughputDataFlowJob.failover=true
throughputDataFlowJob.processCountIntervalSeconds=10
throughputDataFlowJob.concurrentDataProcessThreadCount=3
throughputDataFlowJob.description=\u4E0D\u505C\u6B62\u8FD0\u884C\u7684\u4F5C\u4E1A\u793A\u4F8B
throughputDataFlowJob.disabled=false
throughputDataFlowJob.overwrite=true
throughputDataFlowJob.streamingProcess=true

sequenceDataFlowJob.cron=0/5 * * * * ?
sequenceDataFlowJob.shardingTotalCount=10
sequenceDataFlowJob.shardingItemParameters=0=A,1=B,2=C,3=D,4=E,5=F,6=G,7=H,8=I,9=J
sequenceDataFlowJob.maxTimeDiffSeconds=-1
sequenceDataFlowJob.monitorExecution=true
sequenceDataFlowJob.failover=true
sequenceDataFlowJob.processCountIntervalSeconds=10
sequenceDataFlowJob.description=\u6309\u987A\u5E8F\u4E0D\u505C\u6B62\u8FD0\u884C\u7684\u4F5C\u4E1A\u793A\u4F8B
sequenceDataFlowJob.disabled=false
sequenceDataFlowJob.overwrite=true
```

```java
#reg.properties

serverLists=localhost:4181
namespace=elasticjob-example
baseSleepTimeMilliseconds=1000
maxSleepTimeMilliseconds=3000
maxRetries=3

nestedPort=4181
nestedDataDir=target/test_zk_data/
```

##集成中遇到的问题
###1.cron表达式总是和第一次运行时配置的一样，不变
因为，不论是elastic-job的github给出的示例，还是网上给的示例，配置项都是没有添加overwrite选项的，这个选项默认是false，也就是任务的配置信息，如果已经设置过，那么就会一直不变，就算后续你修改了自己的配置文件中的cron。

解决方法就是在你的job配置中加上overwrite选项：
```java
<job:simple id="yourTaskId" class="yourTaskClass" registry-center-ref="regCenter" cron="0 0/30 * * * ?"   sharding-total-count="1" sharding-item-parameters="0=A" overwrite="true"/>
```


###2.我在网上找到的例子，给的serverLists=" yourhost:2181"，为什么编译器告诉我serverLists配置项不被支持

网上很多示例都是针对1.1.0版本之前的示例，1.1.0版本elastic-job进行了很大的改动，包括一些属性。

解决方法就是，使用1.1.0版本以后的elastic-job，按照github官网给出的示例去做（https://github.com/dangdangdotcom/elastic-job）

###3.我的job里面的autowired或者resource变量没有注入

解决方法，首先看你的变量是不是静态的，如果是静态的请换成非静态的，这时spring的问题。接下来看下你的job有没有添加@component注解。

###4.我是springmvc的web工程，并且已经在其他xml文件有placeholder了，但是reg:zookeeper初始化时显示的连接仍然是“${xxx}”的样式

原理作者也有弄清楚（后续可以研究一下配置文件的加载过程）。如果elastic-job是在单独的xml中配置，那么需要在这个xml中添加placeholder，但是，你一定知道spring默认仅加载一个placeholder，那么只需要在placeholder属性中添加ignore-unresolvable="true"即可。


###5.如果我需要在job中重新设定下次触发的时间怎么办

在你的job中结束位置，添加如下代码：
```java
JobRegistry.getInstance().getJobScheduleController（jobname）.rescheduleJob(cron)；
```
如果，你打印了日志，那么应该会发现，上面的语句调用后，job会被立即触发，看起来像是同时执行了两次。这是触发时间点计算的缘故，cron表达式是以s为单位的，计算机的执行是以毫秒为单位的，很可能当前的时间点仍然是你给定新cron表达式相符合的时间点。

给了具体的例子：

>原有cron="0/10 * * * * * ? "
触发时间点是：9点18分10s
函数执行时间是：100ms
执行的最后调用：reschedule
新的cron="0/5 * * * * * ?"
那么此时仍然符合新cron的触发时间点，所以reschedule会立即触发

这是无法避免的，请保证你的job的幂等性。

##elastic-job不同侧面解析
> 这里首先给出elastic-job主要设计师之一张亮的一篇博文地址，这里给出了很多elastic-job的机理层面的解析。（http://my.oschina.net/u/719192/blog/506062）


###实现思想对比
1.先说下map/reduce的思想，这个看起来和定时任务没有关系，列在这里也正是因为两者之间算是完全不同的两种思想。
![这里写图片描述](http://img.blog.csdn.net/20160619151825844)

这里要特别指出的是，所有的计算节点，都是被动的接受任务，头结点给你什么任务，你就执行什么任务。


2.分布式定时任务（quartz/elastic-job）
接下来看一下定时任务的集群方案，是完全的一个翻转：

![这里写图片描述](http://img.blog.csdn.net/20160619153622537)

所有的任务执行节点上的调度器都在运行，他们执行不执行某个任务，是根据从协调中心获取到的数据判断的。quartz是看数据库记录，elastic-job是看zookeeper中的sharding信息。

3.另外一种思路？
可能你会想，为什么定时任务不能是单独的一个集群，然后可以通过管理端随时上传定时任务的jar上去，然后又头结点调度呢？这样的话不是所有的定时任务都能集中、统一管理起来了么？那该多好，和部署的服务器独立。我只能说，市面上是有这种类型的服务的，由于没有仔细的分析是不是完全一样，这里不给出例子了。（给也不负责，不给也不负责，哎~~）


最后，说明一下，既然知道了分布式定时任务的思想，那么也就很容易理解他的部署方式了：
> 也就是直接和你的web服务在一起，每个服务器实例都是一个计算节点，连接到协调中心（数据库/zookeeper），定时任务触发时从协调中心查询自己是应当执行job任务，还是直接返回，跳过job的执行。


接下来着重从源代码层面的不同侧面做一些对elastic-job的粗范的解析，以利于使用elastic-job时遇到问题的快速解决。

###任务的初始化过程
初始化的入口在：
> new JobScheduler(regCenter, simpleJobConfig, new SimpleDistributeOnceElasticJobListener()).init();

接下来看下init方法到底做了什么事情：

![这里写图片描述](http://img.blog.csdn.net/20160619154817014)

其中最主要的两个步骤是：

1.registerStartUpInfo，这一步，这里面添加了对zookeeper的监听（后续会讲到监听和监听后做了什么），和zookeeper上相关节点的创建。

其中persistJobConfiguration方法中用到了前面问题中说到的overwrite，如果overwrite为false，那么shechule的触发cron表达式是直接从zookeeper中获取的，而不是本地xml配置的。

其中的setReshrdingFlag用来创建一个标记，所有服务器上的同名schedule运行的job都会检查是否存在这个标记（在后续的任务执行中会说到），如果存在，那么执行任务重新分片（后续会说到什么是分片，分片用来干什么，这是elastic-job优于quartz集群的大亮点之一）。

2.sheduleJob
这就是创建quartz的schedule，启动定时任务了。

###任务执行
elastic-job任务分片，多种类型任务的封装都在这里，先看下elastic-job和做为elastic-job基础的quartz之间的关系：

![这里写图片描述](http://img.blog.csdn.net/20160619160634015)


看上图，应该能够很清楚，elastic-job所有的关键都在abstractElasticJob.execute方法中，接下来一块看一下：

![这里写图片描述](http://img.blog.csdn.net/20160619160916238)


看到里面的shardingIfNecessary和getShardingItems.isEmpty-return了么？

这就是分片和控制任务仅被应当执行的服务器实例执行的关键了。

###分片
看了上边那么多，估计很可能你还是对分片是什么，怎么用，什么时候会触发分片存在很多很多的疑问，接下来一个一个的看。

说到分片这可以说是elastic-job在quartz集群调度上的一个创新。在quartz集群环境下，仅有一个服务器实例可以运行某一个特定的schedule。但是在elastic-job下，你可以指定有几个服务器实例执行这一个任务，可以是1个，2个，3个都可以。

那么几个服务器实例运行同一个任务不是冲突了么，至少是浪费了么？NONONO.....

举个例子，在一个更广的环境下，比如你有一个定时计算用户积分的任务，你的用户表是分在10个数据库里的。那么你可以用一个服务器实例去运行，也可以用5个服务器实例去运行，因为你有5台服务器可用，每个服务器实例分给2个数据库的计算任务。

这种场景用quartz是做不到的，用elastic-job，你只需要指定总分片10，那么每一个分片指定一个标记量，那么每台服务器会得到2个任务去执行。

当然如果你有5台服务器可用来计算，但是数据库仅有2个，那么你只能分两个片，那么这5台中有两台得到运行的权利，其他的服务器将在job.execute中看到自己的getShardingItems.isEmpty然后直接return。

###分片在什么场景下会触发呢？

以下场景都会触发重新分片，以下场景是在zookeeper中添加了一个reshard的标记量，任务下次执行的时候就会触发分片。

![这里写图片描述](http://img.blog.csdn.net/20160619162122417)

###监听器的作用

前边说过了，在初始化的时候elastic-job会注册一系列的zookeeper监听器，监听节点的变化，那么他具体监听了哪些地方呢？

![这里写图片描述](http://img.blog.csdn.net/20160619162425275)


汇总起来是两个方面：一个是响应console对定时任务的控制，一个是响应服务器的崩溃。当执行的节点崩溃时，会触发重新分片，由其他服务器接起定时任务的执行。
